data:
  train_raw: "data/toon_marble/marble_train_windows.jsonl"
  train_desc: "data/toon_marble/descriptions_train_toon.jsonl"
  val_raw: "data/toon_marble/marble_test_windows.jsonl"
  val_desc: "data/toon_marble/descriptions_test_toon.jsonl"

  train_features: "data/toon_marble/features_train_zsym.npz"
  val_features:   "data/toon_marble/features_test_zsym.npz"  

  use_rag_description: False

  fs: 1.0                
  duration: 72    

  max_desc_per_channel: 2     
  text_base: >
        Here I describe the sensors from activity recognition.

# El resto del config (modelo, optimización, etc.) lo copias de mhealth_fuzzy.yml
# y sólo cambias num_labels si quieres, o lo infieres desde train_ds.lab2id.


model:
  llama_id: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  chronos_id: amazon/chronos-t5-tiny
  
  #llama_id: meta-llama/Meta-Llama-3-8B-Instruct
  #chronos_id: amazon/chronos-t5-base
  
  text_max_len: 1024
  proj_hidden: 2048
  proj_dropout: 0.2
  head_hidden: 1024
  head_dropout: 0.2
  prompt_prefix: ""

inference:
  llama_precision: 4bit
  chronos_precision: 4bit
  device_map_text: "cuda:0"   # si usas 8bit o multi-GPU, deja que load_models lo resuelva




train:
  epochs: 40
  batch_size: 4
  lr: 1e-4
  weight_decay: 1e-4
  label_smoothing: 0.0
  out_dir: outputs_clean
    